{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8085f465",
   "metadata": {},
   "source": [
    "[Original VQ-VAE paper](https://arxiv.org/pdf/1711.00937)\n",
    "\n",
    "The basic idea:\n",
    "\n",
    "- Take a normal-style VAE Decoder and Encoder\n",
    "- At the bottleneck, use a set of $K$ embedding vectors, $e_k$ of dimensionality $D$\n",
    "    - The vectors have a set latent dimension\n",
    "    - The vectors are learned during training\n",
    "- During inference, the latent vector output by the encoder is mapped to the nearest neighbour embedding vector\n",
    "- gradients flow back, with a straight-through estimator at the embedding layer\n",
    "- For image generation, we learn a 2D grid of embedded features\n",
    "\n",
    "\n",
    "The loss function is given by\n",
    "$$\n",
    "L \\;=\\; \\underbrace{\\log p\\bigl(x \\mid z_q(x)\\bigr)}_{\\text{Reconstruction Loss}}\n",
    "\\;+\\; \\underbrace{\\bigl\\lVert \\mathrm{sg}\\bigl(z_e(x)\\bigr) - e \\bigr\\rVert_{2}^{2}}_{\\text{Codebook Loss}}\n",
    "\\;+\\; \\underbrace{\\beta \\,\\bigl\\lVert z_e(x) - \\mathrm{sg}(e)\\bigr\\rVert_{2}^{2}}_{\\text{Commitment Loss}}.\n",
    "$$\n",
    "\n",
    "Where $sg(\\cdot)$ is the stopgradient operator. The three terms are:\n",
    "\n",
    "1. The Reconstruction Loss trains the encoder and decoder to generate close matches to the input image,\n",
    "2. The Codebook Loss moves the embedding vectors towards embeddings generated by the encoder,\n",
    "3. The Commitment Loss incentivises the encoder to keep latents close to the embedding vectors, rather than expanding out into the space in an unbounded manner.\n",
    "\n",
    "$\\beta$ = 0.25 is a good starting point. The given output shapes of the latent field are 32x32 (ImageNet) and 8x8x10 (Cifar10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a343ff06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "\n",
    "import flax.linen as nn\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "from genlearn.data import get_cifar_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bde4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, valloader = get_cifar_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d66ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 512\n",
    "D = 64\n",
    "latent_shape = (8, 8, 10, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2eb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = random.key(0)\n",
    "key, subkey = random.split(key)\n",
    "embeddings = random.normal(subkey, (K, D))\n",
    "key, subkey = random.split(key)\n",
    "z = random.normal(subkey, latent_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7628878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed(z, embeddings):\n",
    "    'Quantise a single latent vector to its closest codebook latent vector'\n",
    "    def distance(e, z):\n",
    "        'The L2 distance between two vectors'\n",
    "        return jnp.linalg.norm(e - z)\n",
    "\n",
    "    # vectorise to calc over all codebook vectors at once\n",
    "    codebook_distances = jax.vmap(distance, (0, None), 0)(embeddings, z)\n",
    "    nearest_embedding_ix = jnp.argmin(codebook_distances)\n",
    "    return embeddings[nearest_embedding_ix]\n",
    "\n",
    "# with an 8x8x10xD latent space, we need to vmap over all 3 first axes\n",
    "# to fully vectorise the embedding function\n",
    "batch_embed = jax.vmap(embed,       in_axes=(0, None))\n",
    "batch_embed = jax.vmap(batch_embed, in_axes=(0, None))\n",
    "batch_embed = jax.vmap(batch_embed, in_axes=(0, None))\n",
    "batch_embed(z, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde3041c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8, 10, 64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ebe9c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in trainloader:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
